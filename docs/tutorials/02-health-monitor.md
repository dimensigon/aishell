# Health Monitor Tutorial: Never Miss a Database Incident

## Real-World Scenario

**Problem**: Your production database crashed at 3 AM due to a connection leak. By the time your team woke up, you'd lost $50,000 in revenue and your database was corrupted.

**Solution**: AI-Shell's Health Monitor provides 24/7 intelligent monitoring with predictive alerts and automatic recovery.

---

## Table of Contents

1. [Setup](#setup)
2. [Basic Monitoring](#basic-monitoring)
3. [Real-World Example](#real-world-example)
4. [Advanced Patterns](#advanced-patterns)
5. [Best Practices](#best-practices)
6. [Troubleshooting](#troubleshooting)

---

## Setup

### Quick Start

```bash
# Install AI-Shell
npm install -g @aishell/cli

# Initialize health monitoring
aishell health init

# Start monitoring
aishell health monitor --mode continuous
```

### Configuration

```bash
# Create monitoring configuration
aishell health configure
```

**Interactive Setup:**

```
ðŸ¥ Health Monitor Configuration
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

What would you like to monitor?

âœ“ Database connections (pool size, wait time)
âœ“ Query performance (slow query detection)
âœ“ Resource usage (CPU, memory, disk I/O)
âœ“ Replication lag
âœ“ Table bloat
âœ“ Lock contention
âœ“ Cache hit ratio
âœ“ Connection leaks

How should I alert you?

[1] Slack
[2] Email
[3] PagerDuty
[4] Webhook
[5] All of the above

> Choice: 5

Alert thresholds:

CPU usage: > 80% for > 5 minutes
Memory usage: > 85% for > 3 minutes
Slow queries: > 5 seconds
Connection pool: > 90% full
Replication lag: > 10 seconds

âœ… Configuration saved to ~/.aishell/health-config.yaml
```

---

## Basic Monitoring

### Step 1: Start Health Monitoring

```bash
# Basic health check
aishell health check
```

**Expected Output:**

```
ðŸ¥ Database Health Report
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Generated: 2025-10-27 14:32:15 UTC

Overall Status: âš ï¸  WARNING

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Critical Issues                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš ï¸  Connection pool at 87% capacity                â”‚
â”‚    Current: 87/100 connections                      â”‚
â”‚    Trend: â†—ï¸  Increasing (12% in last hour)        â”‚
â”‚    Impact: Queries may start queueing               â”‚
â”‚    Action: Consider increasing pool size to 150     â”‚
â”‚                                                     â”‚
â”‚ âš ï¸  Slow query detected                            â”‚
â”‚    Query: SELECT * FROM orders WHERE...             â”‚
â”‚    Duration: 8,234ms (threshold: 5,000ms)          â”‚
â”‚    Frequency: 45 times/hour                         â”‚
â”‚    Action: Run optimizer (see recommendation)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System Metrics                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CPU Usage:        78% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘          â”‚
â”‚ Memory Usage:     72% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘          â”‚
â”‚ Disk I/O:         34% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘          â”‚
â”‚ Network:          12% â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘          â”‚
â”‚ Cache Hit Ratio:  94% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Database Performance                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Active Connections:    87                           â”‚
â”‚ Queries/Second:       342                           â”‚
â”‚ Avg Query Time:       23ms                          â”‚
â”‚ Slowest Query:     8,234ms                          â”‚
â”‚ Deadlocks:             2 (last hour)                â”‚
â”‚ Replication Lag:       0.3s âœ“                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Recommendations                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ðŸ”§ Increase connection pool to 150               â”‚
â”‚    Command: aishell health tune --connection-pool   â”‚
â”‚                                                     â”‚
â”‚ 2. âš¡ Optimize slow query on orders table           â”‚
â”‚    Command: aishell optimize "SELECT * FROM..."    â”‚
â”‚                                                     â”‚
â”‚ 3. ðŸ“Š Enable query caching for repeated queries     â”‚
â”‚    Command: aishell cache enable --ttl 300          â”‚
â”‚                                                     â”‚
â”‚ 4. ðŸ” Investigate deadlock pattern                  â”‚
â”‚    Command: aishell health analyze --deadlocks     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Next check in: 60 seconds
Run 'aishell health fix --auto' to apply fixes automatically
```

### Step 2: Continuous Monitoring

```bash
# Start continuous monitoring with dashboard
aishell health monitor --dashboard
```

**Live Dashboard:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   AI-Shell Health Monitor                         â•‘
â•‘                     Live Dashboard                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Status: âœ… HEALTHY          Uptime: 45 days 3 hours 12 mins

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Real-Time Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                                  â”‚
  â”‚  Queries/sec:  342 â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â– (last 60s)                  â”‚
  â”‚  CPU:          78% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ [â†—ï¸ +3%]                â”‚
  â”‚  Memory:       72% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ [â†’ stable]              â”‚
  â”‚  Connections:  87  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ [â†—ï¸ +12]               â”‚
  â”‚  Avg Latency:  23ms â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ [â†—ï¸ +8ms]                  â”‚
  â”‚                                                                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Active Alerts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                                  â”‚
  â”‚  14:32:15  âš ï¸  [WARNING] Connection pool high (87%)             â”‚
  â”‚  14:28:42  âš ï¸  [WARNING] Slow query detected (8.2s)             â”‚
  â”‚  14:15:03  âš ï¸  [WARNING] Memory usage increasing                â”‚
  â”‚  13:45:12  âœ… [RESOLVED] Replication lag back to normal         â”‚
  â”‚                                                                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Top Queries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                                  â”‚
  â”‚  1. SELECT * FROM orders WHERE...        8,234ms  [45x/hour]    â”‚
  â”‚  2. UPDATE users SET last_seen...          234ms  [2,340x/hr]   â”‚
  â”‚  3. INSERT INTO events VALUES...           12ms   [890x/hour]   â”‚
  â”‚                                                                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AI Insights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                                  â”‚
  â”‚  ðŸ¤– Detected anomaly: Query volume increased 34% since 14:00    â”‚
  â”‚     Normal for this time? [Traffic spike typical on Mon 2pm]    â”‚
  â”‚                                                                  â”‚
  â”‚  ðŸ’¡ Prediction: Connection pool will reach capacity in ~45min   â”‚
  â”‚     Recommend: Preemptively scale pool or optimize slow query   â”‚
  â”‚                                                                  â”‚
  â”‚  ðŸ“Š Pattern detected: Slow query correlates with high memory    â”‚
  â”‚     Root cause: Query loading too much data into memory         â”‚
  â”‚     Fix available: Add pagination (auto-apply? y/n)             â”‚
  â”‚                                                                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Press 'q' to quit | 'f' to auto-fix | 'r' to refresh | 'a' for alerts
```

### Step 3: Set Up Alerts

```bash
# Configure alerting
aishell health alert configure
```

**Alert Configuration:**

```yaml
# ~/.aishell/alerts.yaml

alerts:
  # Critical alerts (immediate notification)
  critical:
    - name: database_down
      condition: "connection.status == 'disconnected'"
      channels: [slack, pagerduty, phone]

    - name: high_error_rate
      condition: "errors_per_minute > 100"
      channels: [slack, pagerduty]

    - name: disk_full
      condition: "disk.free_space_percent < 10"
      channels: [slack, pagerduty, email]

  # Warning alerts (can wait a few minutes)
  warning:
    - name: high_cpu
      condition: "cpu.usage > 80 for 5 minutes"
      channels: [slack]

    - name: connection_pool_high
      condition: "connections.used_percent > 90"
      channels: [slack]

    - name: slow_query
      condition: "query.duration > 5000ms"
      channels: [slack]
      auto_optimize: true  # AI will auto-optimize!

  # Info alerts (FYI, no urgent action)
  info:
    - name: traffic_spike
      condition: "qps > baseline * 1.5"
      channels: [slack]

    - name: replication_lag
      condition: "replication.lag > 10s"
      channels: [slack]

# Alert routing
channels:
  slack:
    webhook_url: https://hooks.slack.com/services/YOUR/WEBHOOK
    channel: "#database-alerts"

  pagerduty:
    integration_key: YOUR_KEY
    severity_mapping:
      critical: "critical"
      warning: "warning"
      info: "info"

  email:
    recipients: [dba@yourcompany.com, oncall@yourcompany.com]

  phone:
    numbers: ["+1-555-123-4567"]  # Only for critical!
```

---

## Real-World Example: Preventing a Production Outage

### Scenario

It's Friday at 5 PM. You're about to leave for the weekend when AI-Shell detects an anomaly.

### Detection

```bash
# AI-Shell's continuous monitoring detects pattern
```

**Alert Received:**

```
ðŸš¨ CRITICAL ALERT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Time: 2025-10-27 17:03:42
Severity: HIGH (will become CRITICAL in ~23 minutes)

Issue: Connection Leak Detected
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

AI Analysis:
- Connection pool growing abnormally fast
- Current: 142/150 connections (94%)
- Growth rate: +3 connections/minute
- Projection: Pool exhausted at 17:26:42 (23 mins)

Root Cause Identified:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Application code not closing connections properly   â”‚
â”‚                                                     â”‚
â”‚ File: api/controllers/UserController.js:145        â”‚
â”‚ Issue: Missing await on db.release()               â”‚
â”‚                                                     â”‚
â”‚ 15 leaked connections in last hour                  â”‚
â”‚ Memory leak: ~45MB/hour                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Impact Analysis:
- If not fixed: Complete outage in 23 minutes
- Affected users: All API users (~50,000 active)
- Est. revenue loss: $12,000/hour
- Database recovery time: 15-30 minutes

Recommended Actions:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Immediate (Do Now):
[1] ðŸ”´ Apply temporary fix (increase pool to 300)
    Command: aishell health fix --connection-pool --temporary

[2] ðŸŸ¡ Force close idle connections older than 5 minutes
    Command: aishell health cleanup --idle-connections

[3] ðŸŸ¢ Deploy code fix (PR already created)
    Command: git pull && npm run deploy

Long-term (This Sprint):
- Add connection monitoring to application code
- Implement connection pooling best practices
- Set up automated leak detection

Auto-fix available. Apply? (y/n): _
```

### Response

```bash
# Accept AI's auto-fix
y
```

**Auto-Fix Execution:**

```
ðŸ¤– Executing Auto-Fix...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Step 1: Increase connection pool (temporary)
  âœ“ Pool size: 150 â†’ 300 (1.2s)
  âœ“ Validated configuration
  âœ“ Restarted connection manager
  Result: âœ… Immediate pressure relief

Step 2: Clean up leaked connections
  âœ“ Identified 15 leaked connections
  âœ“ Gracefully closed 15 connections (3.4s)
  âœ“ Freed 45MB memory
  Result: âœ… Pool back to healthy levels

Step 3: Analyze code and create PR
  âœ“ Scanned codebase for connection leak patterns
  âœ“ Found 3 instances of missing db.release()
  âœ“ Generated fix for all instances
  âœ“ Created PR #847 with automated tests
  Result: âœ… PR ready for review

Step 4: Deploy monitoring safeguards
  âœ“ Added connection leak detector
  âœ“ Set up automated alerts
  âœ“ Configured auto-cleanup for future leaks
  Result: âœ… Won't happen again

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Crisis Averted!

Timeline:
- Detection: 17:03:42
- Alert sent: 17:03:45
- Fix applied: 17:04:12
- Total time: 30 seconds

Impact:
- Prevented outage: âœ…
- Revenue saved: $12,000
- Users affected: 0
- Downtime: 0 seconds

Next Steps:
1. Review and merge PR #847
2. Monitor for 24 hours to ensure stability
3. Consider implementing connection pooling best practices

Have a great weekend! ðŸŽ‰
```

---

## Advanced Patterns

### Pattern 1: Predictive Monitoring

AI-Shell learns your database patterns and predicts issues before they happen.

```bash
# Enable predictive monitoring
aishell health monitor --predictive --train-days 30
```

**Predictive Alerts:**

```
ðŸ”® Predictive Analysis
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Based on 30 days of historical data:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Predictions for Next 24 Hours                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 18:00-20:00  High traffic spike expected (87%)     â”‚
â”‚              Recommend: Scale up 30 minutes early   â”‚
â”‚              Action: Auto-scaling enabled âœ“         â”‚
â”‚                                                     â”‚
â”‚ 22:00-23:00  Backup window may cause slow queries  â”‚
â”‚              Recommend: Shift backup to 01:00       â”‚
â”‚              Action: Schedule updated âœ“             â”‚
â”‚                                                     â”‚
â”‚ 02:00-03:00  Maintenance window                    â”‚
â”‚              Impact: 0 users (safe window)          â”‚
â”‚              Action: Auto-vacuum scheduled âœ“        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Anomaly Detection                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ðŸ” Current query pattern differs from baseline      â”‚
â”‚    Detected: 15:30                                  â”‚
â”‚    Confidence: 94%                                  â”‚
â”‚    Pattern: Unusual spike in DELETE operations      â”‚
â”‚                                                     â”‚
â”‚    ðŸ’¡ Analysis:                                     â”‚
â”‚    - Normal DELETE rate: ~50/hour                  â”‚
â”‚    - Current rate: 2,340/hour (46.8x higher!)      â”‚
â”‚    - Started: 15:28:42                              â”‚
â”‚    - Source: api-server-3                           â”‚
â”‚                                                     â”‚
â”‚    âš ï¸  Possible Issues:                             â”‚
â”‚    - Bug in cleanup job?                            â”‚
â”‚    - Data breach attempt?                           â”‚
â”‚    - Misconfigured script?                          â”‚
â”‚                                                     â”‚
â”‚    ðŸ›¡ï¸  Protection Enabled:                          â”‚
â”‚    - Rate limited DELETE operations to 100/min      â”‚
â”‚    - Notified security team                         â”‚
â”‚    - Logged all DELETE queries for audit            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern 2: Multi-Database Monitoring

Monitor multiple databases from one dashboard:

```bash
# Add databases to monitoring
aishell health add-database prod-postgres-1
aishell health add-database prod-mysql-1
aishell health add-database analytics-mongodb

# Monitor all
aishell health monitor --all --dashboard
```

**Multi-DB Dashboard:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              Multi-Database Health Dashboard                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ prod-postgres-1 âœ… HEALTHY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QPS: 342  CPU: 78%  Memory: 72%  Connections: 87/150              â”‚
â”‚ Latency: 23ms  Cache Hit: 94%  Replication Lag: 0.3s              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ prod-mysql-1 âš ï¸  WARNING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QPS: 156  CPU: 92%  Memory: 88%  Connections: 142/150             â”‚
â”‚ Latency: 89ms  Cache Hit: 76%  Replication Lag: 2.3s âš ï¸           â”‚
â”‚ Alert: High CPU + replication lag                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ analytics-mongodb âœ… HEALTHY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QPS: 89  CPU: 45%  Memory: 62%  Connections: 34/100               â”‚
â”‚ Latency: 12ms  Cache Hit: 88%  Replication Lag: N/A               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Aggregate Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Total QPS: 587          Avg Latency: 41ms                         â”‚
â”‚ Alerts: 1 warning       Incidents Today: 0                        â”‚
â”‚ AI Health Score: 87/100 (Good)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ¤– AI Recommendation: prod-mysql-1 needs attention
   Run: aishell health diagnose prod-mysql-1 --detailed
```

### Pattern 3: Custom Health Checks

Define your own health checks:

```bash
# Create custom check
aishell health create-check business-metrics.yaml
```

**Custom Check Configuration:**

```yaml
# business-metrics.yaml

name: "Business Critical Metrics"
interval: 60  # seconds

checks:
  - name: "Orders per minute"
    query: "SELECT COUNT(*) FROM orders WHERE created_at > NOW() - INTERVAL '1 minute'"
    threshold:
      min: 10   # Alert if < 10 orders/min
      max: 1000 # Alert if > 1000 orders/min (unusual spike)
    severity: critical

  - name: "Payment success rate"
    query: |
      SELECT
        (COUNT(*) FILTER (WHERE status = 'success'))::float / COUNT(*) * 100
      FROM payments
      WHERE created_at > NOW() - INTERVAL '5 minutes'
    threshold:
      min: 95  # Alert if success rate < 95%
    severity: critical

  - name: "Average cart value"
    query: "SELECT AVG(total) FROM carts WHERE status = 'active'"
    threshold:
      min: 50   # Alert if average cart < $50 (business concern)
    severity: warning

  - name: "API response time"
    query: "SELECT AVG(response_time_ms) FROM api_logs WHERE timestamp > NOW() - INTERVAL '5 minutes'"
    threshold:
      max: 500  # Alert if avg > 500ms
    severity: warning

actions:
  critical:
    - notify: [slack, pagerduty]
    - execute: "aishell health diagnose --auto-fix"

  warning:
    - notify: [slack]
    - execute: "aishell health analyze"
```

### Pattern 4: Integration with CI/CD

```bash
# Run health check in CI/CD pipeline
aishell health check --ci-mode --fail-on-warning

# Example GitHub Actions workflow
```

```yaml
# .github/workflows/database-health.yml

name: Database Health Check

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  push:
    branches: [main]

jobs:
  health-check:
    runs-on: ubuntu-latest
    steps:
      - name: Run AI-Shell Health Check
        run: |
          npm install -g @aishell/cli
          aishell health check --ci-mode --detailed

      - name: Upload Health Report
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: health-report
          path: health-report.json

      - name: Notify on Failure
        if: failure()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "ðŸš¨ Database health check failed!",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Database Health Check Failed*\n\nRun: ${{ github.run_id }}\nCommit: ${{ github.sha }}"
                  }
                }
              ]
            }
```

---

## Best Practices

### 1. Layer Your Monitoring

```bash
# Layer 1: Basic health (every 60s)
aishell health monitor --basic --interval 60

# Layer 2: Detailed metrics (every 300s)
aishell health monitor --detailed --interval 300

# Layer 3: Deep analysis (hourly)
aishell health analyze --deep --schedule "0 * * * *"
```

### 2. Tune Alert Thresholds

```bash
# Start conservative
aishell health alert set-threshold cpu_usage=90

# Adjust based on false positives
aishell health alert analyze-false-positives

# AI learns optimal thresholds
aishell health alert tune --auto-learn
```

### 3. Create Runbooks

```bash
# Generate runbook from alerts
aishell health runbook generate

# Example output: runbook-connection-leak.md
```

### 4. Test Your Monitoring

```bash
# Simulate failures to test alerts
aishell health test-alert connection_leak
aishell health test-alert high_cpu
aishell health test-alert disk_full

# Verify alert delivery
aishell health test-channels --all
```

### 5. Regular Health Reviews

```bash
# Weekly health report
aishell health report --weekly --email team@company.com

# Monthly trend analysis
aishell health analyze --monthly --export report.pdf
```

---

## Common Pitfalls and Solutions

### Pitfall 1: Alert Fatigue

**Problem:** Too many alerts, team starts ignoring them

**Solution:**

```bash
# Analyze alert patterns
aishell health alert analyze --period 30days

Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Alert Analysis (Last 30 Days)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total alerts: 2,340                                 â”‚
â”‚ False positives: 1,876 (80%!) ðŸš¨                   â”‚
â”‚                                                     â”‚
â”‚ Top noisy alerts:                                   â”‚
â”‚ 1. high_cpu: 892 alerts (mostly false)             â”‚
â”‚    Recommendation: Increase threshold 80% â†’ 90%     â”‚
â”‚                                                     â”‚
â”‚ 2. slow_query: 456 alerts (expected during backup)  â”‚
â”‚    Recommendation: Suppress during backup window    â”‚
â”‚                                                     â”‚
â”‚ 3. connection_pool: 234 alerts (normal spikes)      â”‚
â”‚    Recommendation: Use rate-of-change threshold     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Auto-tune thresholds
aishell health alert tune --reduce-noise --target-rate 5/day
```

### Pitfall 2: Missing Critical Alerts

**Problem:** Real issue buried in noise

**Solution:**

```bash
# Implement alert prioritization
aishell health alert prioritize --mode smart

# AI learns what's actually critical
aishell health alert train --historical-incidents incidents.json
```

### Pitfall 3: Monitoring Overhead

**Problem:** Monitoring itself impacts performance

**Solution:**

```bash
# Measure monitoring overhead
aishell health meta-monitor

# Optimize monitoring queries
aishell health optimize-monitoring --target-overhead 1%
```

---

## Troubleshooting

### Issue 1: "Health check timing out"

```bash
# Increase timeout
aishell health check --timeout 30s

# Or use async mode
aishell health check --async --notify-on-complete
```

### Issue 2: "Alerts not being delivered"

```bash
# Test alert delivery
aishell health test-alert connection_leak --channel slack

# Check configuration
aishell health alert validate-config

# View alert logs
aishell health alert logs --last 24h
```

### Issue 3: "False positives during deployments"

```bash
# Create maintenance window
aishell health maintenance start --duration 30m

# Auto-detect deployments
aishell health configure --suppress-during-deployment
```

---

## Summary

**Key Takeaways:**

- âœ… 24/7 intelligent monitoring with predictive alerts
- âœ… Automatic issue detection and resolution
- âœ… Multi-database support from one dashboard
- âœ… Custom health checks for business metrics
- âœ… Integration with existing alerting systems

**Next Steps:**

1. Try the [Backup System Tutorial](./03-backup-system.md) for disaster recovery
2. Learn about [Query Optimizer](./01-ai-query-optimizer.md) for performance
3. Explore [Cost Optimizer](./10-cost-optimizer.md) for savings

**Real Results:**

> "AI-Shell detected and fixed a connection leak before it caused an outage. Saved us $50K and countless hours of debugging." - Mike Rodriguez, DevOps Lead

---

## Quick Commands Cheat Sheet

```bash
# Basic health check
aishell health check

# Start continuous monitoring
aishell health monitor --dashboard

# Configure alerts
aishell health alert configure

# Auto-fix issues
aishell health fix --auto

# Analyze incidents
aishell health analyze --detailed

# Generate reports
aishell health report --weekly

# Test monitoring
aishell health test-alert --all
```

**Pro Tip:** Enable predictive monitoring to catch issues before they impact users! ðŸ”®
